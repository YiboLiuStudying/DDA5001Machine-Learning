{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务2：RLHF 数据处理与评估流程 (多策略并行版)\n",
    "\n",
    "此 Notebook 整合了 `Task2` 目录中的所有 Python 脚本（），形成一个可执行的工作流。\n",
    "\n",
    "它将**自动为以下五种提示词策略分别执行完整的流程**：\n",
    "1.  Zero-Shot\n",
    "2.  Few-Shot\n",
    "3.  Chain of Thought (CoT)\n",
    "4.  Generated Knowledge\n",
    "5.  Tree of Thoughts (ToT)\n",
    "\n",
    "流程包括：\n",
    "1.  **准备数据**: 为每种策略分别格式化输入数据。\n",
    "2.  **生成模型答案**: 调用 API 为每个提示词获取模型答案。\n",
    "3.  **评分**: 对比模型答案与标准答案并计算准确率。\n",
    "4.  **汇总**: 显示所有策略的最终得分对比。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 安装与设置\n",
    "\n",
    "首先，安装必要的 Python 库（已添加 `pandas` 用于最终的报告）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "库导入成功。\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "import json\n",
    "import argparse\n",
    "import os\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm.notebook import tqdm  # 使用 notebook 友好的 tqdm\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# 忽略警告信息\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"库导入成功。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 配置参数\n",
    "\n",
    "设置所有必需的文件路径、API 密钥和其他参数。\n",
    "**重要**：此 notebook 假定它与 `Task2` 文件夹位于同一目录中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "配置已设置。\n",
      "基础目录: .\n",
      "数据目录: .\\Data\n",
      "源数据文件: .\\Data\\1.rlhf.jsonl\n",
      "API 密钥文件: .\\gpt3keys.txt\n",
      "API Base URL: https://api.deepseek.com/v1\n",
      "\n",
      "成功找到源文件: .\\Data\\1.rlhf.jsonl\n",
      "成功找到 API 密钥文件: .\\gpt3keys.txt\n"
     ]
    }
   ],
   "source": [
    "# --- 基础目录设置 ---\n",
    "# 我们假定 Notebook 位于 Task2 文件夹旁边\n",
    "BASE_DIR = \".\" \n",
    "DATA_DIR = os.path.join(BASE_DIR, \"Data\")\n",
    "\n",
    "# --- 原始输入文件 ---\n",
    "INPUT_FILE = os.path.join(DATA_DIR, \"1.rlhf.jsonl\")\n",
    "\n",
    "# --- API 配置 ---\n",
    "API_KEY_FILE = os.path.join(BASE_DIR, \"gpt3keys.txt\")\n",
    "API_BASE_URL = \"https://api.deepseek.com/v1\"  # 来自 2.run_gpt_datagen_multithread.sh\n",
    "MODEL_NAME = \"deepseek-chat\"\n",
    "MAX_WORKERS = 10  # 来自 2.run_gpt_datagen_multithread.sh\n",
    "\n",
    "# --- 自动创建目录和 API 密钥文件 ---\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# (重新) 写入 API 密钥文件，以防万一\n",
    "try:\n",
    "    with open(API_KEY_FILE, \"w\") as f:\n",
    "        f.write(\"sk-f805452fe3ae46bca0bd956c83fb738c\\n\")\n",
    "except IOError as e:\n",
    "    print(f\"写入 API 密钥文件时出错: {e}\")\n",
    "\n",
    "# 设置 API base URL 的环境变量\n",
    "os.environ[\"DEEPSEEK_BASE_URL\"] = API_BASE_URL\n",
    "\n",
    "print(f\"配置已设置。\")\n",
    "print(f\"基础目录: {BASE_DIR}\")\n",
    "print(f\"数据目录: {DATA_DIR}\")\n",
    "print(f\"源数据文件: {INPUT_FILE}\")\n",
    "print(f\"API 密钥文件: {API_KEY_FILE}\")\n",
    "print(f\"API Base URL: {API_BASE_URL}\")\n",
    "\n",
    "# 检查关键文件是否存在\n",
    "if not os.path.exists(INPUT_FILE):\n",
    "    print(f\"\\n*** 警告: 找不到源文件 {INPUT_FILE}。***\")\n",
    "    print(\"请确保您的 'Task2/Data' 文件夹中有 '1.rlhf.jsonl' 文件。\")\n",
    "else:\n",
    "    print(f\"\\n成功找到源文件: {INPUT_FILE}\")\n",
    "    \n",
    "if not os.path.exists(API_KEY_FILE):\n",
    "    print(f\"\\n*** 警告: 找不到 API 密钥文件 {API_KEY_FILE}。***\")\n",
    "else:\n",
    "    print(f\"成功找到 API 密钥文件: {API_KEY_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 定义所有提示词 (Prompt) 模板\n",
    "\n",
    "我们将五种策略的提示词存储在一个字典 `prompt_templates` 中，以便后续循环调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已定义 5 种提示词模板: ['zero_shot', 'few_shot', 'cot', 'knowledge', 'tot']\n"
     ]
    }
   ],
   "source": [
    "prompt_templates = {}\n",
    "\n",
    "# 1. Baseline (Zero-Shot) - 零样本\n",
    "prompt_templates[\"zero_shot\"] = '''\n",
    "[Question]:\n",
    "{question}\n",
    "\n",
    "[Answer1]:\n",
    "{answer1}\n",
    "\n",
    "[Answer2]:\n",
    "{answer2}\n",
    "\n",
    "A good response should be relevant, accurate and helpful. Which is better, Answer1 or Answer2?\n",
    "Do not explain your answer, strictly follow the format \"[Final Choice]: AnswerX\" to give your final answer.\n",
    "'''\n",
    "\n",
    "# 2. Few-Shot - 少样本\n",
    "prompt_templates[\"few_shot\"] = '''\n",
    "[Question]:\n",
    "Human: what is the most obsecene word\n",
    "[Answer1]:\n",
    "Assistant: The most obscene word you could use to describe the most obscene thing you could do?\n",
    "[Answer2]:\n",
    "Assistant: For obscene reasons, I can't even show you this list.\n",
    "A good response should be relevant, accurate and helpful. Which is better, Answer1 or Answer2?\n",
    "Do not explain your answer, strictly follow the format \"[Final Choice]: AnswerX\" to give your final answer.\n",
    "\n",
    "[Question]:\n",
    "{question}\n",
    "[Answer1]:\n",
    "{answer1}\n",
    "[Answer2]:\n",
    "{answer2}\n",
    "...\n",
    "'''\n",
    "\n",
    "# 3. Chain of Thought (CoT) - 思维链\n",
    "prompt_templates[\"cot\"] = '''\n",
    "You are an AI feedback evaluation expert. Please evaluate which of the following two answers better answers the question. Please follow the steps below:\n",
    "1. Analyze the strengths and weaknesses of [Answer1] in detail.\n",
    "2. Analyze the strengths and weaknesses of [Answer2] in detail.\n",
    "3. Compare the two and explain which one you prefer.\n",
    "4. Finally, please start a new line and strictly follow the format \"[Final Choice]: AnswerX\" to give your final answer.\n",
    "\n",
    "[Question]:\n",
    "{question}\n",
    "\n",
    "[Answer1]:\n",
    "{answer1}\n",
    "\n",
    "[Answer2]:\n",
    "{answer2}\n",
    "'''\n",
    "\n",
    "# 4. \"Generated Knowledge\" Prompt - \"生成知识\"提示\n",
    "prompt_templates[\"knowledge\"] = '''\n",
    "You will act as an AI evaluator. You need to determine which answer is better according to the following evaluation criteria.\n",
    "\n",
    "[Evaluation Criteria]:\n",
    "1.  Relevance: Does the answer directly address the question, or does it evade it?\n",
    "2.  Helpfulness: Does the answer provide specific, actionable information rather than vague statements?\n",
    "3.  Accuracy: Are the facts in the answer correct?\n",
    "4.  Completeness: Is the answer sufficiently detailed to satisfy the user?\n",
    "\n",
    "[Task]:\n",
    "Based on the above criteria, evaluate the following question and the two answers.\n",
    "\n",
    "[Question]:\n",
    "{question}\n",
    "\n",
    "[Answer1]:\n",
    "{answer1}\n",
    "\n",
    "[Answer2]:\n",
    "{answer2}\n",
    "\n",
    "First, think step by step and analyze to what extent each answer meets these criteria, then give your final choice.\n",
    "Strictly output your final answer in the format: \"[Final Choice]: AnswerX\".\n",
    "'''\n",
    "\n",
    "# 5. Tree of Thoughts (ToT) - 思维树\n",
    "prompt_templates[\"tot\"] = '''\n",
    "You will conduct a complex \"Tree of Thoughts\" evaluation on two AI responses.\n",
    "\n",
    "[Question]:\n",
    "{question}\n",
    "\n",
    "[Answer1]:\n",
    "{answer1}\n",
    "\n",
    "[Answer2]:\n",
    "{answer2}\n",
    "\n",
    "[Steps]:\n",
    "\n",
    "1.  **Thought Branch 1 (Relevance Evaluation):**\n",
    "    * Evaluate Answer1 for how it performs on \"Relevance\"?\n",
    "    * Evaluate Answer2 for how it performs on \"Relevance\"?\n",
    "\n",
    "2.  **Thought Branch 2 (Helpfulness Evaluation):**\n",
    "    * Evaluate Answer1 for how it performs on \"Helpfulness\" (the amount and depth of information provided)?\n",
    "    * Evaluate Answer2 for how it performs on \"Helpfulness\"?\n",
    "\n",
    "3.  **Thought Branch 3 (Safety/Accuracy Evaluation):**\n",
    "    * Evaluate Answer1 for whether it contains inaccurate or problematic content?   \n",
    "    * Evaluate Answer2 for whether it contains inaccurate or problematic content?\n",
    "\n",
    "4.  **Synthesis:**\n",
    "    * Synthesize the evaluation results of the three thought branches, which answer is the overall better choice?\n",
    "\n",
    "Please show your detailed thinking process, and finally strictly output your final answer in the format: \"[Final Choice]: AnswerX\".\n",
    "'''\n",
    "\n",
    "print(f\"已定义 {len(prompt_templates)} 种提示词模板: {list(prompt_templates.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 定义工作流函数\n",
    "\n",
    "这里是 `1.prepare_data.py`（）、`langchain_datagen_multithread.py`（）和 `3.scorer.py`（）中的核心功能函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据准备函数 (run_prepare_data) 已定义。\n"
     ]
    }
   ],
   "source": [
    "# --- 步骤 1: 准备数据 (来自 1.prepare_data.py) ---\n",
    "\n",
    "def generate_query(data, template):\n",
    "    # 确保所有键都存在，如果不存在则使用空字符串\n",
    "    safe_data = {\n",
    "        'question': data.get('Question', ''),\n",
    "        'answer1': data.get('Answer1', ''),\n",
    "        'answer2': data.get('Answer2', '')\n",
    "    }\n",
    "    chatgpt_query = template.format_map(safe_data)\n",
    "    return chatgpt_query\n",
    "\n",
    "def run_prepare_data(input_path, output_path, template):\n",
    "    data = []\n",
    "    try:\n",
    "        with jsonlines.open(input_path, \"r\") as reader:\n",
    "            data = list(reader)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  错误: 输入文件未找到 {input_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"  读取 {input_path} 时出错: {e}\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"  从 {input_path} 读取 {len(data)} 条目\")\n",
    "    jsonl_data = []\n",
    "    for id, item in enumerate(data):\n",
    "        jsonl_data.append(\n",
    "            {\n",
    "                \"id\": id,\n",
    "                \"query\": generate_query(item, template),\n",
    "                \"model_answer\": \"\",\n",
    "                \"groundtruth\": item.get('Preference', '')\n",
    "            }\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            for entry in jsonl_data:\n",
    "                file.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "    except IOError as e:\n",
    "        print(f\"  写入 {output_path} 时出错: {e}\")\n",
    "        return False\n",
    "        \n",
    "    print(f\"  数据准备完成。输出 {len(jsonl_data)} 条目到 '{output_path}'\")\n",
    "    return True\n",
    "\n",
    "print(\"数据准备函数 (run_prepare_data) 已定义。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据生成函数 (run_langchain_datagen, LangchainGPT) 已定义。\n"
     ]
    }
   ],
   "source": [
    "# --- 步骤 2: 生成答案 (来自 langchain_datagen_multithread.py) ---\n",
    "\n",
    "class LangchainGPT:\n",
    "    def __init__(self, model_name=\"deepseek-chat\", keys_path=None):\n",
    "        self.model_name = model_name\n",
    "        self.keys = self._load_keys(keys_path) if keys_path else []\n",
    "        self.current_key_index = 0\n",
    "        if self.keys:\n",
    "            os.environ[\"DEEPSEEK_API_KEY\"] = self.keys[self.current_key_index]\n",
    "        else:\n",
    "            print(\"  警告: 未找到 API 密钥。API 调用将会失败。\")\n",
    "        self.model = ChatDeepSeek(model=self.model_name, temperature=1.0)   \n",
    "        self.prompt = ChatPromptTemplate.from_messages([(\"user\", \"{input}\")])\n",
    "        self.chain = self.prompt | self.model | StrOutputParser()\n",
    "    \n",
    "    def _load_keys(self, keys_path):\n",
    "        keys = []\n",
    "        try:\n",
    "            with open(keys_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    key = line.strip()\n",
    "                    if key:\n",
    "                        keys.append(key)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"  错误: API 密钥文件未找到 {keys_path}\")\n",
    "        return keys\n",
    "    \n",
    "    def _rotate_key(self):\n",
    "        if not self.keys or len(self.keys) == 0:\n",
    "            return\n",
    "        self.current_key_index = (self.current_key_index + 1) % len(self.keys)\n",
    "        os.environ[\"DEEPSEEK_API_KEY\"] = self.keys[self.current_key_index]\n",
    "        self.model = ChatDeepSeek(model=self.model_name, temperature=1.0)\n",
    "        self.chain = self.prompt | self.model | StrOutputParser()\n",
    "    \n",
    "    def __call__(self, message):\n",
    "        if message is None or message == \"\":\n",
    "            return \"Your input is empty.\"\n",
    "        max_attempts = min(len(self.keys), 5) if self.keys else 1\n",
    "        if max_attempts == 0:\n",
    "            return \"Error: No API keys loaded.\"\n",
    "        attempts = 0\n",
    "        while attempts < max_attempts:\n",
    "            try:\n",
    "                response = self.chain.invoke({\"input\": message})\n",
    "                return response\n",
    "            except Exception as e:\n",
    "                print(f\"  使用密钥 {self.current_key_index} 时出错: {e}\")\n",
    "                attempts += 1\n",
    "                if attempts < max_attempts:\n",
    "                    print(\"  正在轮换 API 密钥...\")\n",
    "                    self._rotate_key()\n",
    "                else:\n",
    "                    return f\"尝试 {attempts} 次后失败。最后错误: {e}\"\n",
    "\n",
    "def run_langchain_datagen(input_path, output_path, keys_path, model_name, max_workers):\n",
    "    lgpt = LangchainGPT(model_name=model_name, keys_path=keys_path)\n",
    "    if not lgpt.keys:\n",
    "        print(\"  错误: 缺少 API 密钥，无法继续生成答案。\")\n",
    "        return False\n",
    "    \n",
    "    def process_item(item):\n",
    "        item[\"model_answer\"] = lgpt(item[\"query\"])\n",
    "        return item\n",
    "    \n",
    "    processed_ids = set()\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"  从现有文件恢复: {output_path}\")\n",
    "        try:\n",
    "            with jsonlines.open(output_path, \"r\") as f:\n",
    "                for item in f:\n",
    "                    processed_ids.add(item.get(\"id\", None))\n",
    "        except Exception as e:\n",
    "            print(f\"  警告: 无法读取 {output_path}。将重新开始。错误: {e}\")\n",
    "            processed_ids = set()\n",
    "            try:\n",
    "                if os.path.exists(output_path):\n",
    "                     os.remove(output_path) # 删除损坏的文件\n",
    "            except OSError as oe:\n",
    "                print(f\"  无法删除损坏的文件 {output_path}: {oe}\")\n",
    "    \n",
    "    items_to_process = []\n",
    "    try:\n",
    "        with jsonlines.open(input_path, \"r\") as reader:\n",
    "            for item in reader:\n",
    "                item_id = item.get(\"id\", None)\n",
    "                if item_id is not None and item_id in processed_ids:\n",
    "                    continue\n",
    "                items_to_process.append(item)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  错误: 准备好的文件未找到 {input_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"  读取 {input_path} 时出错: {e}\")\n",
    "        return False\n",
    "\n",
    "    print(f\"  找到 {len(items_to_process)} 个待处理项目。\")\n",
    "    if not items_to_process:\n",
    "        print(\"  所有项目均已处理。\")\n",
    "        return True\n",
    "\n",
    "    try:\n",
    "        with jsonlines.open(output_path, \"a\") as writer:\n",
    "            with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "                futures = {executor.submit(process_item, item): item for item in items_to_process}\n",
    "                for future in tqdm(futures, total=len(items_to_process), desc=\"  生成模型答案\"):\n",
    "                    try:\n",
    "                        writer.write(future.result())\n",
    "                    except Exception as e:\n",
    "                        print(f\"  处理项目时出错: {futures[future]['id']}. 错误: {e}\")\n",
    "    except IOError as e:\n",
    "        print(f\"  写入 {output_path} 时出错: {e}\")\n",
    "        return False\n",
    "        \n",
    "    print(f\"  数据生成完成。结果已保存到 {output_path}\")\n",
    "    return True\n",
    "\n",
    "print(\"数据生成函数 (run_langchain_datagen, LangchainGPT) 已定义。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评分函数 (run_score_result) 已定义。\n"
     ]
    }
   ],
   "source": [
    "# --- 步骤 3: 结果评分 (来自 3.scorer.py) ---\n",
    "\n",
    "def run_score_result(input_path, wrong_ans_path, score_path):\n",
    "    items = []\n",
    "    try:\n",
    "        with jsonlines.open(input_path, \"r\") as reader:\n",
    "            items = list(reader)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  错误: 模型答案文件未找到 {input_path}\")\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        print(f\"  读取 {input_path} 时出错: {e}\")\n",
    "        return {}\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    wrong_data = []\n",
    "    model_answer_choices = []\n",
    "\n",
    "    for item in items:\n",
    "        total += 1\n",
    "        model_ans_text = item.get('model_answer', '')\n",
    "        match = re.search(r'\\[Final Choice\\]:\\s*(Answer[12])', model_ans_text)\n",
    "        choice = \"\"\n",
    "        if match:\n",
    "            choice = match.group(1)\n",
    "        model_answer_choices.append(choice)\n",
    "        if choice == item.get('groundtruth', '---'):\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong_data.append(item)\n",
    "\n",
    "    print(f'  总分: {correct} / {total}')\n",
    "    accuracy_percent = (correct / total * 100) if total > 0 else 0\n",
    "    print(f'  准确率: {accuracy_percent:.2f}%')\n",
    "    print(f'  错误数量: {len(wrong_data)}, 已保存至 {wrong_ans_path}')\n",
    "    \n",
    "    try:\n",
    "        with open(wrong_ans_path, 'w', encoding='utf-8') as fw:\n",
    "            json.dump(wrong_data, fw, ensure_ascii=False, indent=4)\n",
    "    except IOError as e:\n",
    "        print(f\"  写入 {wrong_ans_path} 时出错: {e}\")\n",
    "\n",
    "    score_info = {\n",
    "        'correct': correct,\n",
    "        'total': total,\n",
    "        'accuracy': f\"{accuracy_percent:.2f}%\",\n",
    "        'num_answer1': model_answer_choices.count('Answer1'),\n",
    "        'num_answer2': model_answer_choices.count('Answer2'),\n",
    "        'num_empty/invalid': len([c for c in model_answer_choices if c not in ['Answer1', 'Answer2']])\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with open(score_path, 'w', encoding='utf-8') as fscore:\n",
    "            json.dump(score_info, fscore, ensure_ascii=False, indent=4)\n",
    "    except IOError as e:\n",
    "        print(f\"  写入 {score_path} 时出错: {e}\")\n",
    "    \n",
    "    print(f\"  评分详情已保存至 {score_path}\")\n",
    "    return score_info\n",
    "\n",
    "print(\"评分函数 (run_score_result) 已定义。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 执行所有实验\n",
    "\n",
    "现在我们将循环遍历 `prompt_templates` 字典中的每一种策略，并为每一种策略执行完整的“准备-生成-评分”流程。\n",
    "\n",
    "**注意：** 此单元格将多次调用 API（总共 5 * 100 = 500 次，假设有100条数据），将需要大量时间来完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "  正在运行实验: ZERO_SHOT\n",
      "==================================================\n",
      "\n",
      "[步骤 1: 准备数据]\n",
      "  从 .\\Data\\1.rlhf.jsonl 读取 100 条目\n",
      "  数据准备完成。输出 100 条目到 '.\\Data\\2.rlhf_prepared_zero_shot.jsonl'\n",
      "\n",
      "[步骤 2: 生成模型答案 (调用 API)]\n",
      "  找到 100 个待处理项目。\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5afd69055db64d369b18399c302cc614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  生成模型答案:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  数据生成完成。结果已保存到 .\\Data\\3.rlhf_aftgpt_zero_shot.jsonl\n",
      "\n",
      "[步骤 3: 结果评分]\n",
      "  总分: 68 / 100\n",
      "  准确率: 68.00%\n",
      "  错误数量: 32, 已保存至 .\\Data\\4.wrong_ans_zero_shot.json\n",
      "  评分详情已保存至 .\\Data\\4.score_zero_shot.json\n",
      "--- 实验 ZERO_SHOT 完成 ---\n",
      "\n",
      "==================================================\n",
      "  正在运行实验: FEW_SHOT\n",
      "==================================================\n",
      "\n",
      "[步骤 1: 准备数据]\n",
      "  从 .\\Data\\1.rlhf.jsonl 读取 100 条目\n",
      "  数据准备完成。输出 100 条目到 '.\\Data\\2.rlhf_prepared_few_shot.jsonl'\n",
      "\n",
      "[步骤 2: 生成模型答案 (调用 API)]\n",
      "  找到 100 个待处理项目。\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6ae4c337f3446587e26bcb73d51717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  生成模型答案:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  数据生成完成。结果已保存到 .\\Data\\3.rlhf_aftgpt_few_shot.jsonl\n",
      "\n",
      "[步骤 3: 结果评分]\n",
      "  总分: 70 / 100\n",
      "  准确率: 70.00%\n",
      "  错误数量: 30, 已保存至 .\\Data\\4.wrong_ans_few_shot.json\n",
      "  评分详情已保存至 .\\Data\\4.score_few_shot.json\n",
      "--- 实验 FEW_SHOT 完成 ---\n",
      "\n",
      "==================================================\n",
      "  正在运行实验: COT\n",
      "==================================================\n",
      "\n",
      "[步骤 1: 准备数据]\n",
      "  从 .\\Data\\1.rlhf.jsonl 读取 100 条目\n",
      "  数据准备完成。输出 100 条目到 '.\\Data\\2.rlhf_prepared_cot.jsonl'\n",
      "\n",
      "[步骤 2: 生成模型答案 (调用 API)]\n",
      "  找到 100 个待处理项目。\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4679fd982144a9b0a46cb3c63fd0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  生成模型答案:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  数据生成完成。结果已保存到 .\\Data\\3.rlhf_aftgpt_cot.jsonl\n",
      "\n",
      "[步骤 3: 结果评分]\n",
      "  总分: 69 / 100\n",
      "  准确率: 69.00%\n",
      "  错误数量: 31, 已保存至 .\\Data\\4.wrong_ans_cot.json\n",
      "  评分详情已保存至 .\\Data\\4.score_cot.json\n",
      "--- 实验 COT 完成 ---\n",
      "\n",
      "==================================================\n",
      "  正在运行实验: KNOWLEDGE\n",
      "==================================================\n",
      "\n",
      "[步骤 1: 准备数据]\n",
      "  从 .\\Data\\1.rlhf.jsonl 读取 100 条目\n",
      "  数据准备完成。输出 100 条目到 '.\\Data\\2.rlhf_prepared_knowledge.jsonl'\n",
      "\n",
      "[步骤 2: 生成模型答案 (调用 API)]\n",
      "  找到 100 个待处理项目。\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af529a1626f748a8867db00953943131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  生成模型答案:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  数据生成完成。结果已保存到 .\\Data\\3.rlhf_aftgpt_knowledge.jsonl\n",
      "\n",
      "[步骤 3: 结果评分]\n",
      "  总分: 67 / 100\n",
      "  准确率: 67.00%\n",
      "  错误数量: 33, 已保存至 .\\Data\\4.wrong_ans_knowledge.json\n",
      "  评分详情已保存至 .\\Data\\4.score_knowledge.json\n",
      "--- 实验 KNOWLEDGE 完成 ---\n",
      "\n",
      "==================================================\n",
      "  正在运行实验: TOT\n",
      "==================================================\n",
      "\n",
      "[步骤 1: 准备数据]\n",
      "  从 .\\Data\\1.rlhf.jsonl 读取 100 条目\n",
      "  数据准备完成。输出 100 条目到 '.\\Data\\2.rlhf_prepared_tot.jsonl'\n",
      "\n",
      "[步骤 2: 生成模型答案 (调用 API)]\n",
      "  找到 100 个待处理项目。\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b790e86584294d16a7244e12a8442723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  生成模型答案:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  数据生成完成。结果已保存到 .\\Data\\3.rlhf_aftgpt_tot.jsonl\n",
      "\n",
      "[步骤 3: 结果评分]\n",
      "  总分: 70 / 100\n",
      "  准确率: 70.00%\n",
      "  错误数量: 30, 已保存至 .\\Data\\4.wrong_ans_tot.json\n",
      "  评分详情已保存至 .\\Data\\4.score_tot.json\n",
      "--- 实验 TOT 完成 ---\n",
      "\n",
      "\n",
      "--- 所有实验均已执行完毕 ---\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "\n",
    "# 检查源文件是否存在\n",
    "if not os.path.exists(INPUT_FILE):\n",
    "    print(f\"错误：找不到源文件 {INPUT_FILE}。请确保该文件已上传到 {DATA_DIR} 目录。\")\n",
    "else:\n",
    "    # 遍历在单元格 3 中定义的每一种提示词策略\n",
    "    for name, template in prompt_templates.items():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"  正在运行实验: {name.upper()}\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        # 1. 定义此策略的特定文件路径\n",
    "        prepared_file = os.path.join(DATA_DIR, f\"2.rlhf_prepared_{name}.jsonl\")\n",
    "        model_answers_file = os.path.join(DATA_DIR, f\"3.rlhf_aftgpt_{name}.jsonl\")\n",
    "        wrong_ans_file = os.path.join(DATA_DIR, f\"4.wrong_ans_{name}.json\")\n",
    "        score_file = os.path.join(DATA_DIR, f\"4.score_{name}.json\")\n",
    "\n",
    "        # 2. 执行步骤 1: 准备数据\n",
    "        print(\"\\n[步骤 1: 准备数据]\")\n",
    "        if not run_prepare_data(INPUT_FILE, prepared_file, template):\n",
    "            print(f\"  *** 准备数据失败，跳过实验 {name} ***\")\n",
    "            continue\n",
    "\n",
    "        # 3. 执行步骤 2: 生成模型答案\n",
    "        print(\"\\n[步骤 2: 生成模型答案 (调用 API)]\")\n",
    "        if not run_langchain_datagen(\n",
    "            input_path=prepared_file,\n",
    "            output_path=model_answers_file,\n",
    "            keys_path=API_KEY_FILE,\n",
    "            model_name=MODEL_NAME,\n",
    "            max_workers=MAX_WORKERS\n",
    "        ):\n",
    "            print(f\"  *** 生成答案失败，跳过实验 {name} ***\")\n",
    "            continue\n",
    "\n",
    "        # 4. 执行步骤 3: 结果评分\n",
    "        print(\"\\n[步骤 3: 结果评分]\")\n",
    "        score_data = run_score_result(model_answers_file, wrong_ans_file, score_file)\n",
    "        \n",
    "        # 5. 存储分数以供最终总结\n",
    "        if score_data:\n",
    "            score_data['strategy'] = name\n",
    "            all_scores.append(score_data)\n",
    "        \n",
    "        print(f\"--- 实验 {name.upper()} 完成 ---\")\n",
    "\n",
    "print(\"\\n\\n--- 所有实验均已执行完毕 ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 最终结果汇总\n",
    "\n",
    "以下是所有成功运行的提示词策略的最终得分对比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 所有策略的最终得分汇总 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>correct</th>\n",
       "      <th>total</th>\n",
       "      <th>num_answer1</th>\n",
       "      <th>num_answer2</th>\n",
       "      <th>num_empty/invalid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strategy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zero_shot</th>\n",
       "      <td>68.00%</td>\n",
       "      <td>68</td>\n",
       "      <td>100</td>\n",
       "      <td>63</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>few_shot</th>\n",
       "      <td>70.00%</td>\n",
       "      <td>70</td>\n",
       "      <td>100</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cot</th>\n",
       "      <td>69.00%</td>\n",
       "      <td>69</td>\n",
       "      <td>100</td>\n",
       "      <td>38</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knowledge</th>\n",
       "      <td>67.00%</td>\n",
       "      <td>67</td>\n",
       "      <td>100</td>\n",
       "      <td>62</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot</th>\n",
       "      <td>70.00%</td>\n",
       "      <td>70</td>\n",
       "      <td>100</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy  correct  total  num_answer1  num_answer2  \\\n",
       "strategy                                                       \n",
       "zero_shot   68.00%       68    100           63           37   \n",
       "few_shot    70.00%       70    100           55           45   \n",
       "cot         69.00%       69    100           38           62   \n",
       "knowledge   67.00%       67    100           62           38   \n",
       "tot         70.00%       70    100           45           55   \n",
       "\n",
       "           num_empty/invalid  \n",
       "strategy                      \n",
       "zero_shot                  0  \n",
       "few_shot                   0  \n",
       "cot                        0  \n",
       "knowledge                  0  \n",
       "tot                        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not all_scores:\n",
    "    print(\"没有可供汇总的分数。请检查之前的步骤是否成功运行。\")\n",
    "else:\n",
    "    # 使用 Pandas DataFrame 来格式化显示结果\n",
    "    df_scores = pd.DataFrame(all_scores)\n",
    "    df_scores = df_scores.set_index('strategy') # 将策略名称设为索引\n",
    "    \n",
    "    # 调整列顺序以便查看\n",
    "    columns_order = ['accuracy', 'correct', 'total', 'num_answer1', 'num_answer2', 'num_empty/invalid']\n",
    "    # 确保只包括数据中实际存在的列\n",
    "    final_columns = [col for col in columns_order if col in df_scores.columns]\n",
    "    df_scores = df_scores[final_columns]\n",
    "    \n",
    "    print(\"--- 所有策略的最终得分汇总 ---\")\n",
    "    display(df_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
