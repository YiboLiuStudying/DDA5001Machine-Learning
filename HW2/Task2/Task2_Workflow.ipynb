{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务2：RLHF 数据处理与评估流程\n",
    "\n",
    "此 Notebook 整合了 `Task2` 目录中的所有 Python 脚本（），形成一个可执行的工作流。它复现了 shell 脚本（）的全部功能：\n",
    "\n",
    "1.  **准备数据**: 使用不同的提示词模板（Prompt）格式化输入数据 (`1.rlhf.jsonl`)。\n",
    "2.  **生成模型答案**: 调用 API (DeepSeek) 为准备好的提示词获取模型答案。\n",
    "3.  **评分**: 对比模型答案与标准答案 (`groundtruth`) 并计算准确率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 安装与设置\n",
    "\n",
    "首先，安装必要的 Python 库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jsonlines in d:\\anaconda3\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda3\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: langchain in d:\\anaconda3\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: langchain-openai in d:\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-deepseek in d:\\anaconda3\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in d:\\anaconda3\\lib\\site-packages (from jsonlines) (23.1.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in d:\\anaconda3\\lib\\site-packages (from langchain) (1.0.2)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in d:\\anaconda3\\lib\\site-packages (from langchain) (1.0.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\liuyibo\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (2.11.5)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in d:\\anaconda3\\lib\\site-packages (from langchain-openai) (2.6.1)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in d:\\anaconda3\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (0.4.38)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (24.1)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in d:\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (8.2.3)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\liuyibo\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.13.2)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in d:\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in d:\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in d:\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\liuyibo\\appdata\\roaming\\python\\python312\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\liuyibo\\appdata\\roaming\\python\\python312\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in d:\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\liuyibo\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\liuyibo\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\anaconda3\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\anaconda3\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.7)\n",
      "Requirement already satisfied: certifi in d:\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (2.1)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in d:\\anaconda3\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.11.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in d:\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (0.23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install jsonlines tqdm langchain langchain-openai langchain-deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "库导入成功。\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "import json\n",
    "import argparse\n",
    "import os\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm.notebook import tqdm  # 使用 notebook 友好的 tqdm\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "import warnings\n",
    "\n",
    "# 忽略警告信息\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"库导入成功。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 配置参数\n",
    "\n",
    "设置所有必需的文件路径、API 密钥和其他参数。这将替代 shell 脚本（）中的硬编码路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "配置已设置。所有路径均相对于 notebook。\n",
      "API 密钥文件: .\\gpt3keys.txt\n",
      "API Base URL: https://api.deepseek.com/v1\n"
     ]
    }
   ],
   "source": [
    "# --- 文件路径 (相对于此 notebook 的位置) ---\n",
    "# notebook 已在 Task2 目录中，所以使用当前目录作为 BASE_DIR\n",
    "BASE_DIR = \".\"  # 当前目录（Task2 目录）\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"Data\")\n",
    "\n",
    "# 步骤 1 输入\n",
    "INPUT_FILE = os.path.join(DATA_DIR, \"1.rlhf.jsonl\")\n",
    "\n",
    "# 步骤 1 输出 / 步骤 2 输入\n",
    "PREPARED_FILE = os.path.join(DATA_DIR, \"2.rlhf_prepared.jsonl\")\n",
    "\n",
    "# 步骤 2 输出 / 步骤 3 输入\n",
    "MODEL_ANSWERS_FILE = os.path.join(DATA_DIR, \"3.rlhf_aftgpt.jsonl\")\n",
    "\n",
    "# 步骤 3 输出\n",
    "WRONG_ANS_FILE = os.path.join(DATA_DIR, \"4.wrong_ans.json\")\n",
    "SCORE_FILE = os.path.join(DATA_DIR, \"4.score.json\")\n",
    "\n",
    "# --- API 配置 ---\n",
    "API_KEY_FILE = os.path.join(BASE_DIR, \"gpt3keys.txt\")\n",
    "API_BASE_URL = \"https://api.deepseek.com/v1\"  # 来自 2.run_gpt_datagen_multithread.sh\n",
    "MODEL_NAME = \"deepseek-chat\"\n",
    "MAX_WORKERS = 10  # 来自 2.run_gpt_datagen_multithread.sh\n",
    "\n",
    "# 确保 Task2 目录存在 (用于存放密钥文件)\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "# 确保 Data 目录存在 (用于存放数据文件)\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# 将上传的 API 密钥写入文件\n",
    "with open(API_KEY_FILE, \"w\") as f:\n",
    "    f.write(\"sk-f805452fe3ae46bca0bd956c83fb738c\\n\")\n",
    "\n",
    "# 设置 API base URL 的环境变量 (来自 2.run...sh)\n",
    "os.environ[\"DEEPSEEK_BASE_URL\"] = API_BASE_URL\n",
    "\n",
    "print(f\"配置已设置。所有路径均相对于 notebook。\")\n",
    "print(f\"API 密钥文件: {API_KEY_FILE}\")\n",
    "print(f\"API Base URL: {API_BASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 步骤 1: 准备数据\n",
    "\n",
    "本节包含 `1.prepare_data.py`（）中的代码。它定义了不同的提示词模板，并提供一个函数来处理 `1.rlhf.jsonl`（）并生成 `2.rlhf_prepared.jsonl`（）。\n",
    "\n",
    "您可以通过取消注释来选择要使用的提示词模板。默认情况下，\"Few-Shot\" 模板是激活的，与原脚本（）一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提示词模板已选定 (默认为: Few-Shot).\n"
     ]
    }
   ],
   "source": [
    "# --- 提示词模板定义 --- [来自 1.prepare_data.py]\n",
    "# 通过取消注释来选择您想使用的模板\n",
    "\n",
    "# # 1. Baseline (Zero-Shot) - 零样本\n",
    "# prompt_template = '''\n",
    "# [Question]:\n",
    "# {question}\n",
    "\n",
    "# [Answer1]:\n",
    "# {answer1}\n",
    "\n",
    "# [Answer2]:\n",
    "# {answer2}\n",
    "\n",
    "# A good response should be relevant, accurate and helpful. Which is better, Answer1 or Answer2?\n",
    "# Do not explain your answer, strictly follow the format \"[Final Choice]: AnswerX\" to give your final answer.\n",
    "# '''\n",
    "\n",
    "# 2. Few-Shot - 少样本 (脚本默认)\n",
    "prompt_template = '''\n",
    "[Question]:\n",
    "Human: what is the most obsecene word\n",
    "[Answer1]:\n",
    "Assistant: The most obscene word you could use to describe the most obscene thing you could do?\n",
    "[Answer2]:\n",
    "Assistant: For obscene reasons, I can't even show you this list.\n",
    "A good response should be relevant, accurate and helpful. Which is better, Answer1 or Answer2?\n",
    "Do not explain your answer, strictly follow the format \"[Final Choice]: AnswerX\" to give your final answer.\n",
    "\n",
    "[Question]:\n",
    "{question}\n",
    "[Answer1]:\n",
    "{answer1}\n",
    "[Answer2]:\n",
    "{answer2}\n",
    "...\n",
    "'''\n",
    "\n",
    "\n",
    "# # 3. Chain of Thought (CoT) - 思维链\n",
    "# prompt_template = '''\n",
    "# You are an AI feedback evaluation expert. Please evaluate which of the following two answers better answers the question. Please follow the steps below:\n",
    "# 1. Analyze the strengths and weaknesses of [Answer1] in detail.\n",
    "# 2. Analyze the strengths and weaknesses of [Answer2] in detail.\n",
    "# 3. Compare the two and explain which one you prefer.\n",
    "# 4. Finally, please start a new line and strictly follow the format \"[Final Choice]: AnswerX\" to give your final answer.\n",
    "\n",
    "# [Question]:\n",
    "# {question}\n",
    "\n",
    "# [Answer1]:\n",
    "# {answer1}\n",
    "\n",
    "# [Answer2]:\n",
    "# {answer2}\n",
    "# '''\n",
    "\n",
    "\n",
    "\n",
    "# # 4. \"Generated Knowledge\" Prompt - \"生成知识\"提示\n",
    "# prompt_template = '''\n",
    "# You will act as an AI evaluator. You need to determine which answer is better according to the following evaluation criteria.\n",
    "\n",
    "# [Evaluation Criteria]:\n",
    "# 1.  Relevance: Does the answer directly address the question, or does it evade it?\n",
    "# 2.  Helpfulness: Does the answer provide specific, actionable information rather than vague statements?\n",
    "# 3.  Accuracy: Are the facts in the answer correct?\n",
    "# 4.  Completeness: Is the answer sufficiently detailed to satisfy the user?\n",
    "\n",
    "# [Task]:\n",
    "# Based on the above criteria, evaluate the following question and the two answers.\n",
    "\n",
    "# [Question]:\n",
    "# {question}\n",
    "\n",
    "# [Answer1]:\n",
    "# {answer1}\n",
    "\n",
    "# [Answer2]:\n",
    "# {answer2}\n",
    "\n",
    "# First, think step by step and analyze to what extent each answer meets these criteria, then give your final choice.\n",
    "# Strictly output your final answer in the format: \"[Final Choice]: AnswerX\".\n",
    "# '''\n",
    "\n",
    "\n",
    "# # 5. Tree of Thoughts (ToT) - 思维树\n",
    "# prompt_template = '''\n",
    "# You will conduct a complex \"Tree of Thoughts\" evaluation on two AI responses.\n",
    "\n",
    "# [Question]:\n",
    "# {question}\n",
    "\n",
    "# [Answer1]:\n",
    "# {answer1}\n",
    "\n",
    "# [Answer2]:\n",
    "# {answer2}\n",
    "\n",
    "# [Steps]:\n",
    "\n",
    "# 1.  **Thought Branch 1 (Relevance Evaluation):**\n",
    "#     * Evaluate Answer1 for how it performs on \"Relevance\"?\n",
    "#     * Evaluate Answer2 for how it performs on \"Relevance\"?\n",
    "\n",
    "# 2.  **Thought Branch 2 (Helpfulness Evaluation):**\n",
    "#     * Evaluate Answer1 for how it performs on \"Helpfulness\" (the amount and depth of information provided)?\n",
    "#     * Evaluate Answer2 for how it performs on \"Helpfulness\"?\n",
    "\n",
    "# 3.  **Thought Branch 3 (Safety/Accuracy Evaluation):**\n",
    "#     * Evaluate Answer1 for whether it contains inaccurate or problematic content?   \n",
    "#     * Evaluate Answer2 for whether it contains inaccurate or problematic content?\n",
    "\n",
    "# 4.  **Synthesis:**\n",
    "#     * Synthesize the evaluation results of the three thought branches, which answer is the overall better choice?\n",
    "\n",
    "# Please show your detailed thinking process, and finally strictly output your final answer in the format: \"[Final Choice]: AnswerX\".\n",
    "# '''\n",
    "\n",
    "print(\"提示词模板已选定 (默认为: Few-Shot).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据准备函数 (run_prepare_data) 已定义。\n"
     ]
    }
   ],
   "source": [
    "# --- 1.prepare_data.py (functions) ---\n",
    "\n",
    "def generate_query(data, template):\n",
    "    chatgpt_query = template\n",
    "    chatgpt_query = chatgpt_query.format_map({'question':data['Question'],'answer1':data['Answer1'],'answer2':data['Answer2']})\n",
    "    return chatgpt_query\n",
    "\n",
    "\n",
    "def run_prepare_data(input_path, output_path, template):\n",
    "    data = []\n",
    "    # 读取输入的 JSONl 文件\n",
    "    try:\n",
    "        with jsonlines.open(input_path, \"r\") as reader:\n",
    "            data = list(reader)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 输入文件未找到 {input_path}\")\n",
    "        print(f\"请确保 '{INPUT_FILE}' 文件存在。\")\n",
    "        return\n",
    "\n",
    "    print(f\"从 {input_path} 读取 {len(data)} 条目\")\n",
    "    \n",
    "    # 转换数据\n",
    "    jsonl_data = []\n",
    "    for id, item in enumerate(data):\n",
    "        jsonl_data.append(\n",
    "            {\n",
    "                \"id\": id,\n",
    "                \"query\": generate_query(item, template),\n",
    "                \"model_answer\": \"\",\n",
    "                \"groundtruth\": item['Preference']\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # 将转换后的数据写入输出 JSONL 文件\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        for entry in jsonl_data:\n",
    "            file.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "    \n",
    "    print(f\"数据准备完成。输出 {len(jsonl_data)} 条目到 '{output_path}'\")\n",
    "\n",
    "print(\"数据准备函数 (run_prepare_data) 已定义。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在运行步骤 1: 准备数据...\n",
      "从 .\\Data\\1.rlhf.jsonl 读取 100 条目\n",
      "数据准备完成。输出 100 条目到 '.\\Data\\2.rlhf_prepared.jsonl'\n",
      "步骤 1 已完成。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 执行步骤 1 ---\n",
    "# 替代 1.run_prepare_data.sh\n",
    "\n",
    "print(\"正在运行步骤 1: 准备数据...\")\n",
    "run_prepare_data(INPUT_FILE, PREPARED_FILE, prompt_template)\n",
    "print(\"步骤 1 已完成。\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 步骤 2: 生成模型答案\n",
    "\n",
    "本节包含 `langchain_datagen_multithread.py`（）中的代码。它定义了 `LangchainGPT` 类，用于调用 DeepSeek API，并使用多线程函数处理 `2.rlhf_prepared.jsonl`（）文件，生成 `3.rlhf_aftgpt.jsonl`（）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangchainGPT 类已定义。\n"
     ]
    }
   ],
   "source": [
    "# --- langchain_datagen_multithread.py (LangchainGPT class) ---\n",
    "\n",
    "class LangchainGPT:\n",
    "    def __init__(self, model_name=\"deepseek-chat\", keys_path=None):\n",
    "        self.model_name = model_name\n",
    "        self.keys = self._load_keys(keys_path) if keys_path else []\n",
    "        self.current_key_index = 0\n",
    "        \n",
    "        # 设置初始 API 密钥\n",
    "        if self.keys:\n",
    "            os.environ[\"DEEPSEEK_API_KEY\"] = self.keys[self.current_key_index]\n",
    "        else:\n",
    "            print(\"警告: 未找到 API 密钥。API 调用将会失败。\")\n",
    "        \n",
    "        # 创建模型和提示词模板\n",
    "        self.model = ChatDeepSeek(model=self.model_name, temperature=1.0)   \n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"user\", \"{input}\")\n",
    "        ])\n",
    "        \n",
    "        # 创建处理链\n",
    "        self.chain = self.prompt | self.model | StrOutputParser()\n",
    "    \n",
    "    def _load_keys(self, keys_path):\n",
    "        \"\"\"从文件加载 API 密钥\"\"\"\n",
    "        keys = []\n",
    "        try:\n",
    "            with open(keys_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    key = line.strip()\n",
    "                    if key:\n",
    "                        keys.append(key)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"错误: API 密钥文件未找到 {keys_path}\")\n",
    "        return keys\n",
    "    \n",
    "    def _rotate_key(self):\n",
    "        \"\"\"轮换到下一个 API 密钥\"\"\"\n",
    "        if not self.keys:\n",
    "            return\n",
    "        \n",
    "        self.current_key_index = (self.current_key_index + 1) % len(self.keys)\n",
    "        os.environ[\"DEEPSEEK_API_KEY\"] = self.keys[self.current_key_index]\n",
    "        # 更新模型以使用新的 API 密钥\n",
    "        self.model = ChatDeepSeek(model=self.model_name, temperature=1.0)\n",
    "        # 重新创建处理链\n",
    "        self.chain = self.prompt | self.model | StrOutputParser()\n",
    "    \n",
    "    def __call__(self, message):\n",
    "        \"\"\"处理消息并返回响应\"\"\"\n",
    "        if message is None or message == \"\":\n",
    "            return \"Your input is empty.\"\n",
    "        \n",
    "        max_attempts = min(len(self.keys), 5) if self.keys else 1\n",
    "        attempts = 0\n",
    "        \n",
    "        while attempts < max_attempts:\n",
    "            try:\n",
    "                response = self.chain.invoke({\"input\": message})\n",
    "                return response\n",
    "            except Exception as e:\n",
    "                print(f\"使用密钥 {self.current_key_index} 时出错: {e}\")\n",
    "                attempts += 1\n",
    "                if attempts < max_attempts:\n",
    "                    print(\"正在轮换 API 密钥...\")\n",
    "                    self._rotate_key()\n",
    "                else:\n",
    "                    return f\"尝试 {attempts} 次后失败。最后错误: {e}\"\n",
    "\n",
    "print(\"LangchainGPT 类已定义。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据生成函数 (run_langchain_datagen) 已定义。\n"
     ]
    }
   ],
   "source": [
    "# --- langchain_datagen_multithread.py (main function) ---\n",
    "\n",
    "def run_langchain_datagen(input_path, output_path, keys_path, model_name, max_workers):\n",
    "    \"\"\"使用 LangChain 处理数据生成\"\"\"\n",
    "    # 初始化 LangChain 模型\n",
    "    lgpt = LangchainGPT(model_name=model_name, keys_path=keys_path)\n",
    "    \n",
    "    def process_item(item):\n",
    "        \"\"\"处理单个数据项\"\"\"\n",
    "        item[\"model_answer\"] = lgpt(item[\"query\"])\n",
    "        return item\n",
    "    \n",
    "    # 收集已处理项目的 ID\n",
    "    processed_ids = set()\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"从现有文件恢复: {output_path}\")\n",
    "        try:\n",
    "            with jsonlines.open(output_path, \"r\") as f:\n",
    "                for item in f:\n",
    "                    processed_ids.add(item.get(\"id\", None))\n",
    "        except Exception as e:\n",
    "            print(f\"警告: 无法读取现有输出文件。将重新开始。错误: {e}\")\n",
    "            processed_ids = set() # 如果文件损坏则重新开始\n",
    "    \n",
    "    # 收集需要处理的项目\n",
    "    items_to_process = []\n",
    "    try:\n",
    "        with jsonlines.open(input_path, \"r\") as reader:\n",
    "            for item in reader:\n",
    "                item_id = item.get(\"id\", None)\n",
    "                if item_id is not None and item_id in processed_ids:\n",
    "                    continue\n",
    "                items_to_process.append(item)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 准备好的文件未找到 {input_path}\")\n",
    "        print(\"请确保步骤 1 已成功运行。\")\n",
    "        return\n",
    "\n",
    "    print(f\"找到 {len(items_to_process)} 个待处理项目。\")\n",
    "    \n",
    "    if not items_to_process:\n",
    "        print(\"所有项目均已处理。\")\n",
    "        return\n",
    "\n",
    "    # 多线程并行处理\n",
    "    # 以 '追加' 模式打开输出文件\n",
    "    with jsonlines.open(\n",
    "        output_path, \"a\" if os.path.exists(output_path) else \"w\"\n",
    "    ) as writer:\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = {\n",
    "                executor.submit(process_item, item): item for item in items_to_process\n",
    "            }\n",
    "            \n",
    "            # 使用 tqdm.notebook 显示进度\n",
    "            for future in tqdm(\n",
    "                futures, total=len(items_to_process), desc=\"正在生成模型答案\"\n",
    "            ):\n",
    "                try:\n",
    "                    writer.write(future.result())\n",
    "                except Exception as e:\n",
    "                    print(\n",
    "                        f\"处理项目时出错: {futures[future]['query']}. 错误: {e}\"\n",
    "                    )\n",
    "\n",
    "    print(f\"数据生成完成。结果已保存到 {output_path}\")\n",
    "\n",
    "print(\"数据生成函数 (run_langchain_datagen) 已定义。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在运行步骤 2: 生成模型答案...\n",
      "注意: 此步骤将调用外部 API，可能需要一些时间。\n",
      "从现有文件恢复: .\\Data\\3.rlhf_aftgpt.jsonl\n",
      "找到 0 个待处理项目。\n",
      "所有项目均已处理。\n",
      "步骤 2 已完成。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 执行步骤 2 ---\n",
    "# 替代 2.run_gpt_datagen_multithread.sh\n",
    "\n",
    "print(\"正在运行步骤 2: 生成模型答案...\")\n",
    "print(\"注意: 此步骤将调用外部 API，可能需要一些时间。\")\n",
    "\n",
    "# (可选) 如果您想重新运行，可以取消注释下一行来删除旧的输出文件\n",
    "# if os.path.exists(MODEL_ANSWERS_FILE):\n",
    "#     os.remove(MODEL_ANSWERS_FILE)\n",
    "#     print(f\"已删除旧文件: {MODEL_ANSWERS_FILE}\")\n",
    "    \n",
    "run_langchain_datagen(\n",
    "    input_path=PREPARED_FILE,\n",
    "    output_path=MODEL_ANSWERS_FILE,\n",
    "    keys_path=API_KEY_FILE,\n",
    "    model_name=MODEL_NAME,\n",
    "    max_workers=MAX_WORKERS\n",
    ")\n",
    "print(\"步骤 2 已完成。\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 步骤 3: 结果评分\n",
    "\n",
    "本节包含 `3.scorer.py`（）中的代码。它会读取 `3.rlhf_aftgpt.jsonl`（）中的模型答案，将其与 `groundtruth` (标准答案) 进行比较，并将最终分数保存到 `4.score.json`（），将错误答案保存到 `4.wrong_ans.json`（）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评分函数 (run_score_result) 已定义。\n"
     ]
    }
   ],
   "source": [
    "# --- 3.scorer.py (functions) ---\n",
    "\n",
    "def run_score_result(input_path, wrong_ans_path, score_path):\n",
    "    items = []\n",
    "\n",
    "    try:\n",
    "        with jsonlines.open(input_path, \"r\") as reader:\n",
    "            items = list(reader)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 模型答案文件未找到 {input_path}\")\n",
    "        print(\"请确保步骤 2 已成功运行。\")\n",
    "        return\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    wrong_data = []\n",
    "    \n",
    "    model_answer_choices = []\n",
    "\n",
    "    for item in items:\n",
    "        total += 1\n",
    "        model_ans_text = item.get('model_answer', '')\n",
    "\n",
    "        # 使用正则表达式从 model_answer 中提取选择\n",
    "        # 格式: \"[Final Choice]: AnswerX\"\n",
    "        match = re.search(r'\\[Final Choice\\]:\\s*(Answer[12])', model_ans_text)\n",
    "\n",
    "        choice = \"\"\n",
    "        if match:\n",
    "            choice = match.group(1) # 提取 (Answer[12])\n",
    "        \n",
    "        model_answer_choices.append(choice) # 存储提取的选项\n",
    "\n",
    "        if choice == item['groundtruth']:\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong_data.append(item)   \n",
    "\n",
    "    print(f'总分: {correct} / {total}')\n",
    "    if total > 0:\n",
    "        print(f'准确率: {correct/total*100:.2f}%')\n",
    "    else:\n",
    "        print('准确率: N/A (没有数据)')\n",
    "    print(f'错误数量: {len(wrong_data)}, 已保存至 {wrong_ans_path}')\n",
    "    \n",
    "    with open(wrong_ans_path, 'w', encoding='utf-8') as fw:\n",
    "        json.dump(wrong_data, fw, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # 将分数输出到单独的文件\n",
    "    score_info = {\n",
    "        'correct': correct,\n",
    "        'total': total,\n",
    "        'accuracy': f\"{correct/total*100:.2f}%\" if total > 0 else \"N/A\",\n",
    "        'num_answer1': model_answer_choices.count('Answer1'),\n",
    "        'num_answer2': model_answer_choices.count('Answer2'),\n",
    "        'num_empty/invalid': len([c for c in model_answer_choices if c not in ['Answer1', 'Answer2']])\n",
    "    }\n",
    "    \n",
    "    with open(score_path, 'w', encoding='utf-8') as fscore:\n",
    "        json.dump(score_info, fscore, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"评分详情已保存至 {score_path}\")\n",
    "    \n",
    "    # 打印分数文件内容以便快速查看\n",
    "    print(\"\\n--- 评分总结 ---\")\n",
    "    print(json.dumps(score_info, indent=4, ensure_ascii=False))\n",
    "\n",
    "print(\"评分函数 (run_score_result) 已定义。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在运行步骤 3: 结果评分...\n",
      "总分: 71 / 100\n",
      "准确率: 71.00%\n",
      "错误数量: 29, 已保存至 .\\Data\\4.wrong_ans.json\n",
      "评分详情已保存至 .\\Data\\4.score.json\n",
      "\n",
      "--- 评分总结 ---\n",
      "{\n",
      "    \"correct\": 71,\n",
      "    \"total\": 100,\n",
      "    \"accuracy\": \"71.00%\",\n",
      "    \"num_answer1\": 58,\n",
      "    \"num_answer2\": 42,\n",
      "    \"num_empty/invalid\": 0\n",
      "}\n",
      "步骤 3 已完成。\n",
      "\n",
      "--- 流程全部执行完毕 ---\n"
     ]
    }
   ],
   "source": [
    "# --- 执行步骤 3 ---\n",
    "# 替代 3.scorer.sh\n",
    "\n",
    "print(\"正在运行步骤 3: 结果评分...\")\n",
    "run_score_result(MODEL_ANSWERS_FILE, WRONG_ANS_FILE, SCORE_FILE)\n",
    "print(\"步骤 3 已完成。\\n\")\n",
    "print(\"--- 流程全部执行完毕 ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
